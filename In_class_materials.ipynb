{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72564f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set page config\n",
    "st.set_page_config(page_title=\"4-Tank System LSTM Forecasting\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üè≠ Neural Network Forecasting: 4-Tank System\")\n",
    "st.markdown(\"### Demonstrating LSTM for Chemical Process Control\")\n",
    "\n",
    "# Sidebar for parameters\n",
    "st.sidebar.header(\"Model Parameters\")\n",
    "sequence_length = st.sidebar.slider(\"Sequence Length (time steps)\", 10, 100, 30)\n",
    "prediction_horizon = st.sidebar.slider(\"Prediction Horizon (steps)\", 1, 50, 10)\n",
    "epochs = st.sidebar.slider(\"Training Epochs\", 10, 100, 50)\n",
    "\n",
    "# Load or generate data\n",
    "@st.cache_data\n",
    "def load_tank_data():\n",
    "    \"\"\"Load the 4-tank system data\"\"\"\n",
    "    try:\n",
    "        # Try to load existing data\n",
    "        levels = pd.read_csv('tank_levels_2.csv')\n",
    "        inputs = pd.read_csv('inputs_2.csv')\n",
    "        \n",
    "        # Combine data\n",
    "        data = pd.merge(levels, inputs, on='Time')\n",
    "        return data\n",
    "    except:\n",
    "        st.error(\"Data files not found. Please run the 4-tank simulation first to generate tank_levels_2.csv and inputs_2.csv\")\n",
    "        return None\n",
    "\n",
    "def prepare_lstm_data(data, sequence_length, prediction_horizon):\n",
    "    \"\"\"Prepare data for LSTM training\"\"\"\n",
    "    # Features: current levels + inputs\n",
    "    features = ['Tank1', 'Tank2', 'Tank3', 'Tank4', 'v1', 'v2']\n",
    "    targets = ['Tank1', 'Tank2', 'Tank3', 'Tank4']\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    \n",
    "    X_scaled = scaler_X.fit_transform(data[features])\n",
    "    y_scaled = scaler_y.fit_transform(data[targets])\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - prediction_horizon + 1):\n",
    "        X.append(X_scaled[i:(i + sequence_length)])\n",
    "        y.append(y_scaled[i + sequence_length:i + sequence_length + prediction_horizon])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler_X, scaler_y\n",
    "\n",
    "def build_lstm_model(input_shape, output_shape):\n",
    "    \"\"\"Build LSTM model architecture\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(np.prod(output_shape), activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    data = load_tank_data()\n",
    "    if data is None:\n",
    "        return\n",
    "    \n",
    "    # Display data overview\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"üìä System Data Overview\")\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=['Tank Levels', 'Input Voltages'],\n",
    "            vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        # Tank levels\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['Tank1'], name='Tank 1', line=dict(color='blue')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['Tank2'], name='Tank 2', line=dict(color='green')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['Tank3'], name='Tank 3', line=dict(color='red')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['Tank4'], name='Tank 4', line=dict(color='cyan')), row=1, col=1)\n",
    "        \n",
    "        # Input voltages\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['v1'], name='v1', line=dict(color='orange')), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=data['Time'], y=data['v2'], name='v2', line=dict(color='purple')), row=2, col=1)\n",
    "        \n",
    "        fig.update_layout(height=600, title_text=\"4-Tank System Dynamics\")\n",
    "        fig.update_xaxes(title_text=\"Time (s)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Height (m)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Voltage (V)\", row=2, col=1)\n",
    "        \n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"üìà Data Statistics\")\n",
    "        st.write(data.describe())\n",
    "    \n",
    "    # Train/Test split\n",
    "    split_ratio = st.sidebar.slider(\"Train/Test Split\", 0.6, 0.9, 0.8)\n",
    "    split_idx = int(len(data) * split_ratio)\n",
    "    \n",
    "    train_data = data[:split_idx]\n",
    "    test_data = data[split_idx:]\n",
    "    \n",
    "    st.subheader(\"ü§ñ LSTM Model Training\")\n",
    "    \n",
    "    if st.button(\"üöÄ Train LSTM Model\"):\n",
    "        with st.spinner(\"Training LSTM model...\"):\n",
    "            # Prepare data\n",
    "            X_train, y_train, scaler_X, scaler_y = prepare_lstm_data(train_data, sequence_length, prediction_horizon)\n",
    "            X_test, y_test, _, _ = prepare_lstm_data(test_data, sequence_length, prediction_horizon)\n",
    "            \n",
    "            # Build model\n",
    "            model = build_lstm_model((sequence_length, 6), (prediction_horizon, 4))\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(\n",
    "                X_train, y_train.reshape(y_train.shape[0], -1),\n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = y_pred.reshape(y_pred.shape[0], prediction_horizon, 4)\n",
    "            \n",
    "            # Inverse transform\n",
    "            y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 4)).reshape(y_test.shape)\n",
    "            y_pred_orig = scaler_y.inverse_transform(y_pred.reshape(-1, 4)).reshape(y_pred.shape)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(y_test_orig.flatten(), y_pred_orig.flatten())\n",
    "            mae = mean_absolute_error(y_test_orig.flatten(), y_pred_orig.flatten())\n",
    "            \n",
    "            # Display results\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"MSE\", f\"{mse:.6f}\")\n",
    "            with col2:\n",
    "                st.metric(\"MAE\", f\"{mae:.6f}\")\n",
    "            with col3:\n",
    "                st.metric(\"RMSE\", f\"{np.sqrt(mse):.6f}\")\n",
    "            \n",
    "            # Plot training history\n",
    "            fig_history = go.Figure()\n",
    "            fig_history.add_trace(go.Scatter(y=history.history['loss'], name='Training Loss'))\n",
    "            fig_history.add_trace(go.Scatter(y=history.history['val_loss'], name='Validation Loss'))\n",
    "            fig_history.update_layout(title=\"Training History\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")\n",
    "            st.plotly_chart(fig_history, use_container_width=True)\n",
    "            \n",
    "            # Plot predictions vs actual\n",
    "            st.subheader(\"üéØ Predictions vs Actual\")\n",
    "            \n",
    "            # Show predictions for first few test samples\n",
    "            n_samples = min(5, len(y_test_orig))\n",
    "            \n",
    "            for tank in range(4):\n",
    "                fig_pred = go.Figure()\n",
    "                \n",
    "                for i in range(n_samples):\n",
    "                    time_steps = np.arange(prediction_horizon)\n",
    "                    fig_pred.add_trace(go.Scatter(\n",
    "                        x=time_steps, \n",
    "                        y=y_test_orig[i, :, tank], \n",
    "                        name=f'Actual Sample {i+1}',\n",
    "                        line=dict(dash='solid')\n",
    "                    ))\n",
    "                    fig_pred.add_trace(go.Scatter(\n",
    "                        x=time_steps, \n",
    "                        y=y_pred_orig[i, :, tank], \n",
    "                        name=f'Predicted Sample {i+1}',\n",
    "                        line=dict(dash='dash')\n",
    "                    ))\n",
    "                \n",
    "                fig_pred.update_layout(\n",
    "                    title=f\"Tank {tank+1} Predictions\",\n",
    "                    xaxis_title=\"Time Steps\",\n",
    "                    yaxis_title=\"Height (m)\"\n",
    "                )\n",
    "                st.plotly_chart(fig_pred, use_container_width=True)\n",
    "    \n",
    "    # Interactive prediction\n",
    "    st.subheader(\"üéÆ Interactive Prediction\")\n",
    "    st.markdown(\"Adjust current conditions and see LSTM predictions:\")\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        h1_current = st.slider(\"Current Tank 1 Level (m)\", 0.0, 1.0, 0.3)\n",
    "        h2_current = st.slider(\"Current Tank 2 Level (m)\", 0.0, 1.0, 0.3)\n",
    "        h3_current = st.slider(\"Current Tank 3 Level (m)\", 0.0, 1.0, 0.2)\n",
    "        h4_current = st.slider(\"Current Tank 4 Level (m)\", 0.0, 1.0, 0.2)\n",
    "    \n",
    "    with col2:\n",
    "        v1_current = st.slider(\"Current v1 (V)\", 0.0, 10.0, 5.0)\n",
    "        v2_current = st.slider(\"Current v2 (V)\", 0.0, 10.0, 5.0)\n",
    "        \n",
    "    st.info(\"üí° **Learning Objectives:**\")\n",
    "    st.markdown(\"\"\"\n",
    "    - **Time Series Forecasting**: Predict future tank levels based on current state\n",
    "    - **Multivariate Input**: Use both tank levels and control inputs\n",
    "    - **Process Control**: Understand how inputs affect system dynamics\n",
    "    - **Model Validation**: Compare predictions with actual process behavior\n",
    "    - **Hyperparameter Tuning**: Adjust sequence length, prediction horizon, epochs\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "180/180 [==============================] - 4s 10ms/step - loss: 0.0433 - val_loss: 0.0214\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0343 - val_loss: 0.0212\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0340 - val_loss: 0.0246\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0325 - val_loss: 0.0201\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0322 - val_loss: 0.0196\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0192\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0310 - val_loss: 0.0192\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0302 - val_loss: 0.0286\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0228\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0283 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0180\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0262 - val_loss: 0.0235\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0256 - val_loss: 0.0186\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0247 - val_loss: 0.0218\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0173\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0239 - val_loss: 0.0168\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0231 - val_loss: 0.0223\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0220 - val_loss: 0.0312\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0217 - val_loss: 0.0249\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0206 - val_loss: 0.0244\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0265\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0287\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0346\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0337\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0383\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0351\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0322\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0403\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0370\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0348\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0303\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0341\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0392\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0382\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0317\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0347\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0347\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0304\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0433\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0365\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0343\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0433\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0366\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0360\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0426\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0427\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0433\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0395\n",
      "Saving model and components...\n",
      "‚úÖ Model saved successfully!\n",
      "Files created:\n",
      "- lstm_4tank_model.h5 (main model)\n",
      "- x_scaler.pkl (input scaler)\n",
      "- y_scaler.pkl (output scaler)\n",
      "- model_metadata.pkl (parameters)\n",
      "- training_history.pkl (training history)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uqmkonar\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "\n",
      "Predicted tank levels:\n",
      "Tank1: 0.0442 m\n",
      "Tank2: 0.1817 m\n",
      "Tank3: 0.0703 m\n",
      "Tank4: 0.1660 m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ===== TRAINING THE MODEL =====\n",
    "# Load data\n",
    "df = pd.read_csv(\"inputs_2.csv\", sep=',')\n",
    "df = df.drop('Time', axis=1)\n",
    "\n",
    "# Define input and output columns\n",
    "input_cols = ['v1', 'v2']\n",
    "output_cols = ['Tank1', 'Tank2', 'Tank3', 'Tank4']\n",
    "\n",
    "# Extract values\n",
    "X_raw = df[input_cols].values\n",
    "y_raw = df[output_cols].values\n",
    "\n",
    "# Scale inputs and outputs separately\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X_scaled = x_scaler.fit_transform(X_raw)\n",
    "y_scaled = y_scaler.fit_transform(y_raw)\n",
    "\n",
    "# Convert to LSTM sequences\n",
    "def create_sequences(X, y, window=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(window, len(X)):\n",
    "        X_seq.append(X[i-window:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "window = 10\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, window)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))  # Output for 4 tanks\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# ===== SAVING THE MODEL AND COMPONENTS =====\n",
    "\n",
    "print(\"Saving model and components...\")\n",
    "\n",
    "# 1. Save the Keras model (RECOMMENDED)\n",
    "model.save('lstm_4tank_model.h5')  # Saves architecture + weights + optimizer state\n",
    "# OR for newer format:\n",
    "# model.save('lstm_4tank_model.keras')\n",
    "\n",
    "# 2. Save the scalers using joblib (THIS IS CORRECT)\n",
    "joblib.dump(x_scaler, 'x_scaler.pkl')\n",
    "joblib.dump(y_scaler, 'y_scaler.pkl')\n",
    "\n",
    "# 3. Save model metadata and parameters\n",
    "model_metadata = {\n",
    "    'window_size': window,\n",
    "    'input_cols': input_cols,\n",
    "    'output_cols': output_cols,\n",
    "    'model_architecture': {\n",
    "        'lstm_units': [64, 64],\n",
    "        'dropout_rate': 0.2,\n",
    "        'dense_units': 4\n",
    "    },\n",
    "    'training_params': {\n",
    "        'epochs': 50,\n",
    "        'batch_size': 32,\n",
    "        'validation_split': 0.1\n",
    "    },\n",
    "    'input_shape': X_train.shape,\n",
    "    'output_shape': y_train.shape\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "joblib.dump(model_metadata, 'model_metadata.pkl')\n",
    "\n",
    "# 4. Optional: Save training history\n",
    "joblib.dump(history.history, 'training_history.pkl')\n",
    "\n",
    "print(\"‚úÖ Model saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"- lstm_4tank_model.h5 (main model)\")\n",
    "print(\"- x_scaler.pkl (input scaler)\")\n",
    "print(\"- y_scaler.pkl (output scaler)\")\n",
    "print(\"- model_metadata.pkl (parameters)\")\n",
    "print(\"- training_history.pkl (training history)\")\n",
    "\n",
    "# ===== LOADING AND USING THE SAVED MODEL =====\n",
    "\n",
    "def load_trained_model():\n",
    "    \"\"\"Load the complete trained model with all components\"\"\"\n",
    "    \n",
    "    # Load the Keras model\n",
    "    loaded_model = load_model('lstm_4tank_model.h5')\n",
    "    \n",
    "    # Load the scalers\n",
    "    loaded_x_scaler = joblib.load('x_scaler.pkl')\n",
    "    loaded_y_scaler = joblib.load('y_scaler.pkl')\n",
    "    \n",
    "    # Load metadata\n",
    "    loaded_metadata = joblib.load('model_metadata.pkl')\n",
    "    \n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    return loaded_model, loaded_x_scaler, loaded_y_scaler, loaded_metadata\n",
    "\n",
    "def predict_tank_levels(model, x_scaler, y_scaler, metadata, input_sequence):\n",
    "    \"\"\"\n",
    "    Make predictions using the loaded model\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded Keras model\n",
    "        x_scaler: Loaded input scaler\n",
    "        y_scaler: Loaded output scaler\n",
    "        metadata: Model metadata\n",
    "        input_sequence: New input data [v1, v2] for last 'window_size' time steps\n",
    "    \n",
    "    Returns:\n",
    "        Predicted tank levels [Tank1, Tank2, Tank3, Tank4]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scale the input\n",
    "    input_scaled = x_scaler.transform(input_sequence)\n",
    "    \n",
    "    # Reshape for LSTM (add batch dimension)\n",
    "    input_reshaped = input_scaled.reshape(1, metadata['window_size'], len(metadata['input_cols']))\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_scaled = model.predict(input_reshaped, verbose=0)\n",
    "    \n",
    "    # Inverse transform to get actual tank levels\n",
    "    prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "    \n",
    "    return prediction[0]  # Remove batch dimension\n",
    "\n",
    "# Example usage of the loaded model\n",
    "if __name__ == \"__main__\":\n",
    "    # Test loading\n",
    "    try:\n",
    "        loaded_model, loaded_x_scaler, loaded_y_scaler, loaded_metadata = load_trained_model()\n",
    "        \n",
    "        # Example prediction with new data\n",
    "        # Create example input sequence (last 10 time steps of v1, v2)\n",
    "        example_input = np.array([\n",
    "            [5.0, 3.0],  # v1=5V, v2=3V\n",
    "            [5.1, 3.1],\n",
    "            [5.2, 3.0],\n",
    "            [5.0, 2.9],\n",
    "            [4.9, 3.0],\n",
    "            [5.0, 3.1],\n",
    "            [5.1, 3.0],\n",
    "            [5.0, 3.0],\n",
    "            [5.0, 3.0],\n",
    "            [5.0, 3.0]   # Most recent values\n",
    "        ])\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_levels = predict_tank_levels(\n",
    "            loaded_model, loaded_x_scaler, loaded_y_scaler, \n",
    "            loaded_metadata, example_input\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nPredicted tank levels:\")\n",
    "        for i, tank in enumerate(loaded_metadata['output_cols']):\n",
    "            print(f\"{tank}: {predicted_levels[i]:.4f} m\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Model files not found: {e}\")\n",
    "        print(\"Please run the training code first to save the model.\")\n",
    "\n",
    "# ===== FOR STREAMLIT DEPLOYMENT =====\n",
    "\n",
    "def create_streamlit_model_loader():\n",
    "    \"\"\"\n",
    "    Create a function specifically for loading in Streamlit\n",
    "    \"\"\"\n",
    "    \n",
    "    @st.cache_resource\n",
    "    def load_model_for_streamlit():\n",
    "        return load_trained_model()\n",
    "    \n",
    "    return load_model_for_streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
